# 🐉 Train Your Dragon: README

## 📖 What Is This Course?

**"Train Your Dragon"** is a comprehensive, hands-on training program for individuals and teams who want to master the full lifecycle of building, fine-tuning, evaluating, and deploying their own custom Large Language Model (LLM).

It’s designed for developers, data scientists, ML engineers, and technical leads who want:

* Local control of their AI agents
* Deep understanding of how LLMs learn, think, and hallucinate
* Production-grade tooling for building intelligent systems

Whether you’re launching a startup LLM assistant, embedding autocomplete in your IDE, or leading an enterprise R\&D effort—this course equips you to build real, useful, safe, and optimized models from the ground up.

---

## ❓ Why Build Your Own LLM?

Most companies depend on closed models (like OpenAI, Anthropic), but:

* They can’t explain their predictions
* They hallucinate frequently with code
* Their knowledge can’t be updated or grounded in your docs
* They incur ongoing costs and compliance risk

A **custom-trained LLM** gives you:

* 🎯 More relevant outputs for your exact domain (e.g. coroutine-heavy Rust, DSLs, workflows)
* 🔐 Private, air-gapped inference with no API costs
* ⚙️ Full control of training, updates, and finetuning
* 🧠 The ability to teach your model exactly how you think

---

## 🔧 How Does the Course Work?

The course is broken into 26 progressive modules covering:

1. LLM theory, architecture, and vocabulary
2. Dataset engineering and prompt curation
3. Fine-tuning with Unsloth, PEFT, QLoRA
4. Hallucination minimisation strategies
5. Retrieval-Augmented Generation (RAG)
6. Evaluation, tool integration, and model lifecycle management

You’ll:

* Learn theory
* Complete hands-on labs
* Create and curate your own datasets
* Train and improve your own models
* Deploy models into your favourite development tools (JetBrains, VSCode, CLI)

---

## 🎯 Outcomes for Students and Teams

By the end of the course, **you or your team will be able to**:

* ✅ Train a coroutine-first coding model for Rust, Python, and TypeScript
* ✅ Build and refine prompt-driven and RAG-enhanced systems
* ✅ Evaluate hallucination rates and control model behaviour
* ✅ Serve models locally or on your LAN with full observability
* ✅ Integrate custom LLMs into internal developer tools
* ✅ Teach others how to do the same — scaling your AI capabilities

---

## 🛠 Requirements

* Basic Python knowledge
* Git + CLI familiarity
* Access to a Mac M1/M2, Linux machine, or WSL2 with 16GB RAM minimum
* 8 GB+ VRAM GPU preferred (or access to RunPod/Colab/T4 for labs)

---

## 🧭 Ready to Begin?

Start with [Module 0: Orientation](../modules/OO_orientation/README.md) and we’ll guide you through from zero to your first model.

Let’s train your dragon.
