# ğŸ‰ Train Your Dragon: README

## ğŸ“– What Is This Course?

**"Train Your Dragon"** is a comprehensive, hands-on training program for individuals and teams who want to master the full lifecycle of building, fine-tuning, evaluating, and deploying their own custom Large Language Model (LLM).

Itâ€™s designed for developers, data scientists, ML engineers, and technical leads who want:

* Local control of their AI agents
* Deep understanding of how LLMs learn, think, and hallucinate
* Production-grade tooling for building intelligent systems

Whether youâ€™re launching a startup LLM assistant, embedding autocomplete in your IDE, or leading an enterprise R\&D effortâ€”this course equips you to build real, useful, safe, and optimized models from the ground up.

---

## â“ Why Build Your Own LLM?

Most companies depend on closed models (like OpenAI, Anthropic), but:

* They canâ€™t explain their predictions
* They hallucinate frequently with code
* Their knowledge canâ€™t be updated or grounded in your docs
* They incur ongoing costs and compliance risk

A **custom-trained LLM** gives you:

* ğŸ¯ More relevant outputs for your exact domain (e.g. coroutine-heavy Rust, DSLs, workflows)
* ğŸ” Private, air-gapped inference with no API costs
* âš™ï¸ Full control of training, updates, and finetuning
* ğŸ§  The ability to teach your model exactly how you think

---

## ğŸ”§ How Does the Course Work?

The course is broken into 26 progressive modules covering:

1. LLM theory, architecture, and vocabulary
2. Dataset engineering and prompt curation
3. Fine-tuning with Unsloth, PEFT, QLoRA
4. Hallucination minimisation strategies
5. Retrieval-Augmented Generation (RAG)
6. Evaluation, tool integration, and model lifecycle management

Youâ€™ll:

* Learn theory
* Complete hands-on labs
* Create and curate your own datasets
* Train and improve your own models
* Deploy models into your favourite development tools (JetBrains, VSCode, CLI)

---

## ğŸ¯ Outcomes for Students and Teams

By the end of the course, **you or your team will be able to**:

* âœ… Train a coroutine-first coding model for Rust, Python, and TypeScript
* âœ… Build and refine prompt-driven and RAG-enhanced systems
* âœ… Evaluate hallucination rates and control model behaviour
* âœ… Serve models locally or on your LAN with full observability
* âœ… Integrate custom LLMs into internal developer tools
* âœ… Teach others how to do the same â€” scaling your AI capabilities

---

## ğŸ›  Requirements

* Basic Python knowledge
* Git + CLI familiarity
* Access to a Mac M1/M2, Linux machine, or WSL2 with 16GB RAM minimum
* 8 GB+ VRAM GPU preferred (or access to RunPod/Colab/T4 for labs)

---

## ğŸ§­ Ready to Begin?

Start with [Module 0: Orientation](../modules/OO_orientation/README.md) and weâ€™ll guide you through from zero to your first model.

Letâ€™s train your dragon.
