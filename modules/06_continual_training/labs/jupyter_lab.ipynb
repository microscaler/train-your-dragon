{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÅ Continual Training Lab: Delta Dataset Fine-Tuning\n",
    "In this notebook, you will:\n",
    "- Load hallucination failure cases\n",
    "- Add corrected outputs\n",
    "- Save a delta dataset\n",
    "- Retrain the model on just the patch\n",
    "- Prompt for re-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Load Previous Evaluation Failures"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "with open('logs/hallucination_eval_results.json') as f:\n",
    "    results = json.load(f)\n",
    "failures = [r for r in results if r['hallucinated']]\n",
    "print(f\"Loaded {len(failures)} hallucinated examples.\")\n",
    "failures[:1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Add Corrected Outputs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Replace <insert correct answer here> manually or use GPT assistance\n",
    "corrected = []\n",
    "for f in failures:\n",
    "    corrected.append({\n",
    "        \"instruction\": f[\"prompt\"],\n",
    "        \"output\": \"<insert correct answer here>\"\n",
    "    })\n",
    "\n",
    "with open(\"data/hallucination_corrections.jsonl\", \"w\") as out:\n",
    "    for ex in corrected:\n",
    "        out.write(json.dumps(ex) + \"\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Fine-Tune Using Delta Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/zephyr-1.3b-bnb-4bit',\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "delta = load_dataset(\"json\", data_files=\"data/hallucination_corrections.jsonl\")['train']\n",
    "delta = delta.map(lambda ex: {'prompt': ex['instruction'], 'completion': ex['output']})\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./checkpoints/model_v1.1',\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    fp16=True,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "model.train_model(dataset=delta, args=args)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Evaluate After Retraining"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Model updated. Please re-run hallucination_eval.ipynb with ./checkpoints/model_v1.1\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

