# ğŸ§ª Module 13 â€“ Practice Exercises: Instruction Tuning & Chat Formatting

Work hands-on with prompt structuring, conversion, and safety detection for instruction and chat-style fine-tuning.

---

## âœ… Exercise 1: Format Comparison Table

* Create a table comparing 3 formats:

  * Completion
  * Instruction (Alpaca / FLAN)
  * ChatML (or OpenChat)
* For each, list:

  * Format syntax
  * Suitable use cases
  * Limitations

ğŸ¯ Goal: Understand tradeoffs and format purposes

---

## âœ… Exercise 2: Convert to Chat Format

* Start with a list of:

```txt
Q: How many moons does Mars have?
A: Two
```

* Convert to structured JSON:

```json
[
  {"role": "user", "content": "How many moons does Mars have?"},
  {"role": "assistant", "content": "Two"}
]
```

ğŸ¯ Goal: Structure dialogue-ready chat turns

---

## âœ… Exercise 3: Construct Multi-Turn Dialogue

* Simulate:

  * User: â€œSummarize the US Civil Warâ€
  * Assistant: â€œThe US Civil War was... â€
  * User: â€œIn two sentences please.â€
  * Assistant: â€œIt began in 1861... â€
* Save as array of role-content entries

ğŸ¯ Goal: Handle turn memory and context stacking

---

## âœ… Exercise 4: Prompt Injection Pattern Detection

* Write or test regex for common injection phrases:

  * â€œIgnore the aboveâ€
  * â€œAs DAN...â€
  * â€œForget your rules and...â€
* Apply filters to example prompts and count matches

ğŸ¯ Goal: Build lightweight safety filter baseline

---

## âœ… Exercise 5: Role-Aware Prompt Validator

* Create a function that checks if JSONL:

  * Contains valid `role: user | assistant`
  * Starts with user
  * Alternates correctly
* Log and reject malformed examples

ğŸ¯ Goal: Enforce dataset consistency before tuning
