# ðŸ§ª Module 04 Quiz: Fine-Tuning LLMs

Test your understanding of LoRA, QLoRA, and the Unsloth training flow.

---

### âœ… Instructions

* Choose the best answer for each multiple-choice question.
* Reflect on the open-ended question to connect with your project goals.

---

### 1. What does LoRA stand for?

A. Local Optimized Random Attention
B. Low-Rank Adapter
C. Long-Range Aggregator
D. Lightweight Output Reinforcement Algorithm

**Correct Answer:** B

---

### 2. What is one benefit of QLoRA over regular LoRA?

A. It trains more parameters from scratch
B. It uses quantized models to reduce memory usage
C. It is only available for GPU clusters
D. It allows unrestricted editing of attention weights

**Correct Answer:** B

---

### 3. In the Unsloth workflow, what does `FastLanguageModel.train_model()` do?

A. Creates token embeddings
B. Loads a config from HuggingFace
C. Starts the actual training process
D. Samples tokens from the dataset

**Correct Answer:** C

---

### 4. What should you check if your training crashes with CUDA OOM?

A. Upgrade your GPU firmware
B. Lower batch size or use fewer training examples
C. Remove all tokenizer configs
D. Use a higher learning rate

**Correct Answer:** B

---

### 5. Reflection:

> What type of code examples or reasoning patterns do you want your model to learn?
> Write 1â€“2 sentences in your learner journal and identify how youâ€™ll represent that in your training data.
